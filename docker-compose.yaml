services:
    gluetun:
        container_name: gluetun
        image: ghcr.io/qdm12/gluetun:latest
        restart: unless-stopped
        cap_add:
            - NET_ADMIN
        devices:
            - /dev/net/tun:/dev/net/tun
        volumes:
            - ./gluetun:/gluetun
        environment:
            - VPN_SERVICE_PROVIDER=custom
            - VPN_TYPE=wireguard
            - VPN_ENDPOINT_IP=146.70.217.98
            - VPN_ENDPOINT_PORT=51820
            - WIREGUARD_PUBLIC_KEY=${WIREGUARD_PUBKEY}
            - WIREGUARD_PRIVATE_KEY=${WIREGUARD_PRIVKEY}
            - WIREGUARD_ADDRESSES='10.2.0.2/32'
            - TZ=America/Chicago
            - VPN_PORT_FORWARDING=on
            - VPN_PORT_FORWARDING_PROVIDER=protonvpn
        ports:
            - 8080:8080
            - 6565:6565
    qbittorrent:
        volumes:
            - /data/media/torrents/:/data/media/torrents
            - ./qbittorrent:/config
        depends_on:
            - gluetun
        environment:
            - PUID=1000
            - PGID=1000
        container_name: qbittorrent
        network_mode: container:gluetun
        restart: always
        image: lscr.io/linuxserver/qbittorrent:latest
    # qbit-natmap:
    #     image: ghcr.io/soxfor/qbittorrent-natmap:latest
    #     container_name: qbit-natmap
    #     restart: unless-stopped
    #     depends_on:
    #         - gluetun
    #     network_mode: container:gluetun
    #     volumes:
    #         - /run/containerd/containerd.sock:/var/run/docker.sock:ro
    #     environment:
    #         - TZ=America/Chicago
    #         - QBITTORRENT_SERVER=10.2.0.2
    #         - QBITTORRENT_PORT=8080
    #         - QBITTORRENT_USER=marcus
    #         - QBITTORRENT_PASS=${QBIT_PASS}
    #         - VPN_CT_NAME=gluetun
    #         - VPN_IF_NAME=tun0
    #         - VPN_GATEWAY=10.2.0.1
    #         - CHECK_INTERVAL=300
    #         - NAT_LEASE_LIFETIME=300
    radarr:
        container_name: radarr
        restart: unless-stopped
        ports:
            - "7878:7878"
        volumes:
            - ./radarr:/config
            - /data/media:/data/media
        environment:
            - PUID=1000
            - PGID=1000
            - TZ=America/Chicago
        image: linuxserver/radarr

    sonarr:
        container_name: sonarr
        restart: unless-stopped
        ports:
            - "8989:8989"
        volumes:
            - ./sonarr:/config
            - /data/media:/data/media
        environment:
            - PUID=1000
            - PGID=1000
            - TZ=America/Chicago
        image: linuxserver/sonarr
    prowlarr:
        container_name: prowlarr
        restart: unless-stopped
        ports:
            - 9696:9696
        environment:
            - PUID=1000
            - PGID=1000
            - TZ="America/Chicago"
        volumes:
            - ./prowlarr:/config
        image: ghcr.io/hotio/prowlarr:latest
    jackett:
        container_name: jackett
        restart: unless-stopped
        ports:
            - "9117:9117"
        volumes:
            - ./jackett:/config
        environment:
            - AUTO_UPDATE=true
            - PUID=1000
            - PGID=1000
            - TZ=America/Chicago
        image: lscr.io/linuxserver/jackett:latest

    flaresolverr:
        container_name: flaresolverr
        restart: unless-stopped
        ports:
            - 8191:8191
        image: ghcr.io/flaresolverr/flaresolverr:latest

    ombi:
        image: linuxserver/ombi
        container_name: ombi
        environment:
            - PUID=1000
            - PGID=1000
            - TZ=America/Chicago
        volumes:
            - ./ombi:/config
        ports:
            - "3579:3579"
        restart: unless-stopped

    tautulli:
        image: linuxserver/tautulli
        container_name: tautulli
        environment:
            - PUID=1000
            - PGID=1000
            - TZ=America/Chicago
        volumes:
            - ./tautulli:/config
            - /var/lib/plexmediaserver/Library/Application Support/Plex Media Server/Logs:/logs
        ports:
            - "8181:8181"
        restart: unless-stopped

    bazarr:
        image: linuxserver/bazarr
        container_name: bazarr
        restart: unless-stopped
        ports:
            - "6767:6767"
        environment:
            - PUID=1000
            - PGID=1000
            - TZ=America/Chicago
            - DOCKER_MODS=wayller/bazarr-mod-subsync:latest
        volumes:
            - ./bazarr:/config
            - /data/media/Movies:/data/media/Movies
            - /data/media/TV:/data/media/TV

    unpackerr:
        container_name: unpackerr
        image: golift/unpackerr
        environment:
            - PUID=1000
            - PGID=1000
            - TZ=America/Chicago
            - UN_DEBUG=false
            - DEBUG=yes
            - UN_SONARR_0_URL=http://sonarr:8989
            - UN_SONARR_PATHS_0=/data/torrents/completed/tv
            - UN_SONARR_0_API_KEY=${SONARR_API}
            - UN_RADARR_0_URL=http://radarr:7878
            - UN_RADARR_PATHS_0=/data/torrents/completed/movies
            - UN_RADARR_0_API_KEY=${RADARR_API}
            - UN_LOG_FILE=/data/logs/log.txt
            - UN_FOLDER_0_MOVE_BACK=true
        volumes:
            - ./unpackerr/config:/config
            - /data/media/:/data/media
            - ./unpackerr/logs:/data/logs
        restart: unless-stopped

    bitwarden:
        container_name: bitwarden
        image: vaultwarden/server
        environment:
            # - SIGNUPS_ALLOWED=true
            - DOMAIN=https://bitwarden.yanello.net/
            - SIGNUPS_ALLOWED=FALSE
            - WEBSOCKET_ENABLED=true
            - SMTP_HOST=smtp.gmail.com
            - SMTP_PORT=587
            - SMTP_FROM='marcus.yanello@gmail.com'
            - SMTP_USERNAME=${BW_SMTP_USER}
            - SMTP_PASSWORD=${BW_SMTP_PASS}
            - LOG_FILE=/data/bitwarden.log
        ports:
            - 8343:80
            - 3012:3012
        volumes:
            - ./bitwarden:/data
        restart: unless-stopped

    frigate:
        container_name: frigate
        image: ghcr.io/blakeblackshear/frigate:stable
        restart: unless-stopped
        shm_size: "80mb"
        devices:
            - /dev/apex_0:/dev/apex_0
        volumes:
            - ./frigate/config:/config
            - /zpool/cameras:/media/frigate
            - ./frigate/labelmap.txt:/labelmap.txt
            - type: tmpfs
              target: /tmp/cache
              tmpfs:
                  size: 1000000000
        ports:
            - 5000:5000
            - 1935:1935
        environment:
            - FRIGATE_RTSP_PASSWORD=${FRIGATE_PASSWORD}
            - PLUS_API_KEY=${FRIGATE_API_KEY}
        deploy:
            resources:
                reservations:
                    devices:
                        - driver: nvidia
                          count: 1
                          capabilities: [gpu]

    doubletake:
        container_name: doubletake
        restart: unless-stopped
        image: jakowenko/double-take
        volumes:
            - ./doubletake:/.storage
        ports:
            - 2999:3000
    compreface-postgres-db:
        image: ${registry}compreface-postgres-db:${POSTGRES_VERSION}
        restart: unless-stopped
        container_name: "compreface-postgres-db"
        environment:
            - POSTGRES_USER=${postgres_username}
            - POSTGRES_PASSWORD=${postgres_password}
            - POSTGRES_DB=${postgres_db}
        volumes:
            - ./compreface:/var/lib/postgresql/data
    compreface-admin:
        restart: unless-stopped
        image: ${registry}compreface-admin:${ADMIN_VERSION}
        container_name: "compreface-admin"
        environment:
            - POSTGRES_USER=${postgres_username}
            - POSTGRES_PASSWORD=${postgres_password}
            - POSTGRES_URL=jdbc:postgresql://${postgres_domain}:${postgres_port}/${postgres_db}
            - SPRING_PROFILES_ACTIVE=dev
            - ENABLE_EMAIL_SERVER=${enable_email_server}
            - EMAIL_HOST=${email_host}
            - EMAIL_USERNAME=${email_username}
            - EMAIL_FROM=${email_from}
            - EMAIL_PASSWORD=${email_password}
            - ADMIN_JAVA_OPTS=${compreface_admin_java_options}
            - MAX_FILE_SIZE=${max_file_size}
            - MAX_REQUEST_SIZE=${max_request_size}B

    compreface-api:
        restart: unless-stopped
        image: ${registry}compreface-api:${API_VERSION}
        container_name: "compreface-api"
        environment:
            - POSTGRES_USER=${postgres_username}
            - POSTGRES_PASSWORD=${postgres_password}
            - POSTGRES_URL=jdbc:postgresql://${postgres_domain}:${postgres_port}/${postgres_db}
            - SPRING_PROFILES_ACTIVE=dev
            - API_JAVA_OPTS=${compreface_api_java_options}
            - SAVE_IMAGES_TO_DB=${save_images_to_db}
            - MAX_FILE_SIZE=${max_file_size}
            - MAX_REQUEST_SIZE=${max_request_size}B
            - CONNECTION_TIMEOUT=${connection_timeout:-10000}
            - READ_TIMEOUT=${read_timeout:-60000}
    compreface-fe:
        restart: unless-stopped
        image: ${registry}compreface-fe:${FE_VERSION}
        container_name: "compreface-ui"
        ports:
            - "8000:80"
        environment:
            - CLIENT_MAX_BODY_SIZE=${max_request_size}
            - PROXY_READ_TIMEOUT=${read_timeout:-60000}ms
            - PROXY_CONNECT_TIMEOUT=${connection_timeout:-10000}ms
    compreface-core:
        restart: unless-stopped
        image: ${registry}compreface-core:${CORE_VERSION}
        container_name: "compreface-core"
        environment:
            - ML_PORT=2999
            - IMG_LENGTH_LIMIT=${max_detect_size}
            - UWSGI_PROCESSES=${uwsgi_processes:-2}
            - UWSGI_THREADS=${uwsgi_threads:-1}

    ytdl:
        environment:
            - ALLOW_CONFIG_MUTATIONS=true
            - ytdl_mongodb_connection_string=mongodb://ytdl-mongo-db:27017
            - ytdl_use_local_db=false
            - write_ytdl_config=true
            - ytdl_multi_user_mode=true
            - ytdl_allow_registration=false
        restart: unless-stopped
        volumes:
            - ./ytdl/appdata:/app/appdata
            - ./ytdl/audio:/app/audio
            - ./ytdl/video:/app/video
            - ./ytdl/subscriptions:/app/subscriptions
            - ./ytdl/users:/app/users
        ports:
            - 8998:17442
        image: tzahi12345/youtubedl-material:latest
        container_name: ytdl
    ytdl-mongo-db:
        image: mongo
        container_name: ytdl-mongo-db
        restart: unless-stopped
        volumes:
            - ./ytdl/db/:/data/db

    homebox:
        container_name: homebox
        image: ghcr.io/hay-kot/homebox:latest
        restart: unless-stopped
        environment:
            - HBOX_LOG_LEVEL=info
            - HBOX_LOG_FORMAT=text
            - HBOX_WEB_MAX_UPLOAD_SIZE=10
            - HBOX_OPTIONS_ALLOW_REGISTRATION=false
        volumes:
            - ./hbox:/data
        ports:
            - 3100:7745

    nextcloud:
        container_name: nextcloud
        image: nextcloud:29.0.8
        networks:
            nextcloud_net:
                ipv4_address: 172.20.0.5
        extra_hosts:
            - "nextcloud.yanello.net:172.20.0.5"
        environment:
            - TRUSTED_PROXIES=192.168.1.1
            - OVERWRITECLIURL=https://nextcloud.yanello.net/
            - OVERWRITEHOST=nextcloud.yanello.net
            - OVERWRITEPROTOCOL=https
            - APACHE_DISABLE_REWRITE_IP=1
            - TRUSTED_DOMAINS=yanello.net
            - MYSQL_PASSWORD=${DB_PASSWORD}
            - MYSQL_DATABASE=nextcloud
            - MYSQL_HOST=nextcloud_db
            - MYSQL_USER=nextcloud
            - REDIS_HOST=nextcloud_redis
        volumes:
            - ./nextcloud/app:/var/www/html
            - /zpool/Synced_Folder/Finance/cospend:/var/www/html/data/marcus/files/Documents/cospend
            #- /zpool/share:/var/www/html/data/marcus/files/Share
            - /zpool/share:/zpool/share
            - ./nextcloud/remoteip.conf:/etc/apache2/conf-enabled/remoteip.conf:ro
            - ./nextcloud/redis-session.ini:/usr/local/etc/php/conf.d/redis-session.ini
        ports:
            - 6987:80
            - 6988:443
        restart: unless-stopped
    nextcloud_db:
        container_name: nextcloud_db
        image: mariadb:10.11
        networks:
            - nextcloud_net
        command: --transaction-isolation=READ-COMMITTED --log-bin=binlog --binlog-format=ROW
        volumes:
            - ./nextcloud/db:/var/lib/mysql
        environment:
            - MYSQL_ROOT_PASSWORD=${DB_ROOT_PASSWORD}
            - MYSQL_PASSWORD=${DB_PASSWORD}
            - MYSQL_USER=nextcloud
            - MYSQL_DATABASE=nextcloud
        ports:
            - 3306:3306
        restart: unless-stopped
    nextcloud_redis:
        networks:
            - nextcloud_net
        container_name: nextcloud_redis
        image: redis:alpine
        restart: unless-stopped

    #    your_spotify:
    #        container_name: your_spotify
    #        image: lscr.io/linuxserver/your_spotify:latest
    #        environment:
    #        - PUID=1000
    #        - PGID=1000
    #        - TZ=America/Chicago
    #        - APP_URL=https://spotify.yanello.net
    #        - SPOTIFY_PUBLIC=${SPOTIFY_PUBLIC}
    #        - SPOTIFY_SECRET=${SPOTIFY_SECRET}
    #        - MONGO_ENDPOINT=mongodb://mongo_spotify:27017/your_spotify
    #        ports:
    #        - 3871:80
    #        - 3872:443
    #        restart: unless-stopped
    #        depends_on:
    #        - mongo_spotify
    #        links:
    #        - mongo_spotify
    #    mongo_spotify:
    #        container_name: mongo_spotify
    #        image: mongo
    #        restart: unless-stopped
    #        volumes:
    #        - ./your_spotify/db:/data/db

    overseerr:
        container_name: overseerr
        image: lscr.io/linuxserver/overseerr:latest
        environment:
            - PUID=1000
            - PGID=1000
            - TZ=America/Chicago
        volumes:
            - ./overseerr:/config
        ports:
            - 5055:5055
        restart: unless-stopped

    immich-server:
        container_name: immich-server
        image: ghcr.io/immich-app/immich-server:${IMMICH_VERSION:-release}
        deploy:
            resources:
                reservations:
                    devices:
                        - capabilities:
                              - gpu
                              - compute
                              - video
                          count: 1
                          driver: nvidia
        volumes:
            - /zpool/Photos/immich:/usr/src/app/upload
        env_file:
            - ./env/immich.env
        ports:
            - 2283:2283
            - 3003:3000
        restart: unless-stopped
    immich-machine-learning:
        container_name: immich-machine-learning
        image: ghcr.io/immich-app/immich-machine-learning:${IMMICH_VERSION:-release}-cuda
        volumes:
            - /zpool/Photos/immich:/usr/src/app/upload
            - ./immich/model-cache:/cache
        restart: unless-stopped
        deploy:
            resources:
                reservations:
                    devices:
                        - driver: nvidia
                          count: 1
                          capabilities:
                              - gpu
        env_file:
            - ./env/immich.env
    typesense:
        container_name: typesense
        image: typesense/typesense:0.24.0
        environment:
            - TYPESENSE_API_KEY=${TYPESENSE_API_KEY}
            - TYPESENSE_DATA_DIR=/data
        volumes:
            - ./immich/tsdata:/data
        restart: unless-stopped
    immich-redis:
        container_name: immich-redis
        image: redis:6.2
        restart: unless-stopped
    immich-postgres:
        container_name: immich-postgres
        image: tensorchord/pgvecto-rs:pg14-v0.2.0@sha256:90724186f0a3517cf6914295b5ab410db9ce23190a2d9d0b9dd6463e3fa298f0
        environment:
            - POSTGRES_PASSWORD=${DB_PASSWORD}
            - POSTGRES_USER=${DB_USERNAME}
            - POSTGRES_DB=${DB_DATABASE_NAME}
            - PG_DATA=/var/lib/postgresql/data
        command:
            [
                "postgres",
                "-c",
                "shared_preload_libraries=vectors.so",
                "-c",
                'search_path="$$user", public, vectors',
                "-c",
                "logging_collector=on",
                "-c",
                "max_wal_size=2GB",
                "-c",
                "shared_buffers=512MB",
                "-c",
                "wal_compression=on",
            ]
        ports:
            - 5432:5432
        volumes:
            - ./immich/pgdata:/var/lib/postgresql/data
        restart: unless-stopped

    victoria-metrics:
        container_name: victoria-metrics
        restart: unless-stopped
        image: victoriametrics/victoria-metrics
        ports:
            - 8428:8428
        volumes:
            - ./victoria-metrics:/victoria-metrics-data
            - ./vmagent:/vmagent
        command:
            - "--retentionPeriod=50y"
            - "--influx.databaseNames=iotawatt"
            - "--promscrape.config=/vmagent/vmprometheus/prometheus.yml"
            - "--promscrape.configCheckInterval=1m"
    grafana:
        container_name: grafana
        image: grafana/grafana-enterprise
        ports:
            - 4000:3000
        volumes:
            - ./grafana:/var/lib/grafana
            - /zpool/Synced_Folder/Finance/cospend:/opt/cospend
        user: "1000"
        restart: unless-stopped
        environment:
            - GF_AUTH_ANONYMOUS_ENABLED=true
            - GF_SECURITY_ALLOW_EMBEDDING=true
        #- GF_SECURITY_COOKIE_SAMESITE=none
    #    dcgm_exporter:
    #       container_name: dcgm
    #       image: nvcr.io/nvidia/k8s/dcgm-exporter:3.1.8-3.1.5-ubuntu20.04
    #       deploy:
    #         resources:
    #           reservations:
    #             devices:
    #             - driver: nvidia
    #               count: 1
    #               capabilities: [gpu]
    #       volumes:
    #       - ./dcgm:/etc/dcgm-exporter/
    #       cap_add:
    #       - SYS_ADMIN
    #       restart: unless-stopped
    #       ports:
    #       - 9400:9400
    node_exporter:
        container_name: node-exporter
        image: quay.io/prometheus/node-exporter:latest
        command:
            - "--collector.systemd"
            - "--collector.processes"
            - "--path.rootfs=/host"
        network_mode: host
        pid: host
        restart: unless-stopped
        volumes:
            - /:/host:ro,rslave

    influx1:
        container_name: influx1
        image: influxdb:1.8.10
        restart: unless-stopped
        ports:
            - 8087:8086
        volumes:
            - ./influx1:/var/lib/influxdb
        environment:
            - INFLUXDB_ADMIN_USER=admin
            - INFLUX_DG_ADMIN_PASSWORD=${DB_PASSWORD}
            - INFLUXDB_DB=home
            - INFLUXDB_WRITE_USER=user
            - INFLUXDB_WRITE_USER_PASSWORD=${DB_PASSWORD}

    # netbox:
    #     image: docker.io/netboxcommunity/netbox:latest
    #     container_name: netbox
    #     ports:
    #     - 8001:8080
    #     depends_on:
    #     - netbox-postgres
    #     - netbox-redis
    #     - netbox-redis-cache
    #     env_file: ./env/.netbox.env
    #     user: unit:root
    #     volumes:
    #     - ./netbox/conf:/etc/netbox/config:z,ro
    #     - ./netbox/media:/opt/netbox/netbox/media:z,rw
    #     - ./netbox/reports:/opt/netbox/netbox/reports:z,rw
    #     - ./netbox/scripts:/opt/netbox/netbox/scripts:z,rw
    #     healthcheck:
    #         start_period: 60s
    #         timeout: 3s
    #         interval: 15s
    #         test: "curl -f http://localhost:8080/api/ || exit 1"
    # netbox-worker:
    #     container_name: netbox-worker
    #     image: docker.io/netboxcommunity/netbox:latest
    #     env_file: ./env/.netbox.env
    #     user: unit:root
    #     volumes:
    #     - ./netbox/conf:/etc/netbox/config:z,ro
    #     - ./netbox/media:/opt/netbox/netbox/media:z,rw
    #     - ./netbox/reports:/opt/netbox/netbox/reports:z,rw
    #     - ./netbox/scripts:/opt/netbox/netbox/scripts:z,rw
    #     depends_on:
    #         netbox:
    #             condition: service_healthy
    #     command:
    #     - /opt/netbox/venv/bin/python
    #     - /opt/netbox/netbox/manage.py
    #     - rqworker
    #     healthcheck:
    #         start_period: 20s
    #         timeout: 3s
    #         interval: 15s
    #         test: "ps -aux | grep -v grep | grep -q rqworker || exit 1"
    # netbox-housekeeping:
    #     container_name: netbox-housekeeping
    #     image: docker.io/netboxcommunity/netbox:latest
    #     env_file: ./env/.netbox.env
    #     user: unit:root
    #     volumes:
    #     - ./netbox/conf:/etc/netbox/config:z,ro
    #     - ./netbox/media:/opt/netbox/netbox/media:z,rw
    #     - ./netbox/reports:/opt/netbox/netbox/reports:z,rw
    #     - ./netbox/scripts:/opt/netbox/netbox/scripts:z,rw
    #     depends_on:
    #         netbox:
    #             condition: service_healthy
    #     command:
    #     - /opt/netbox/housekeeping.sh
    #     healthcheck:
    #         start_period: 20s
    #         timeout: 3s
    #         interval: 15s
    #         test: "ps -aux | grep -v grep | grep -q housekeeping || exit 1"
    # netbox-postgres:
    #     image: docker.io/postgres:15-alpine
    #     container_name: netbox-postgres
    #     env_file: ./env/.netbox-postgres.env
    #     volumes:
    #     - ./netbox/postgres:/var/lib/postgresql/data
    # netbox-redis:
    #     image: docker.io/redis:7-alpine
    #     container_name: netbox-redis
    #     env_file: ./env/.netbox-redis-cache.env
    #     command:
    #     - sh
    #     - -c
    #     - redis-server --requirepass $$REDIS_PASSWORD
    # netbox-redis-cache:
    #     container_name: netbox-redis-cache
    #     image: docker.io/redis:7-alpine
    #     command:
    #     - sh
    #     - -c
    #     - redis-server --requirepass $$REDIS_PASSWORD
    #     env_file: ./env/.netbox-redis-cache.env
    #     volumes:
    #     - ./netbox/redis-cache:/data

    # stirling-pdf:
    #     container_name: spdf
    #     image: frooodle/s-pdf:latest
    #     ports:
    #     - 8912:8080
    #     volumes:
    #     - ./spdf/training:/usr/share/tesseract-ocr/4.00/tessdata
    #     - ./spdf/configs:/configs
    #     - ./spdf/files:/customFiles
    #     environment:
    #     - DOCKER_ENABLE_SECURITY=false

    #    quartz:
    #        container_name: quartz
    #        build:
    #            context: ./quartz
    #            dockerfile: Dockerfile
    #        volumes:
    #        - ./quartz:/usr/src/app
    #        - /zpool/Synced_Folder/Notes/Technical:/usr/src/app/content
    #        ports:
    #        - 9911:8080
    #        restart: unless-stopped

    postgres-resume:
        image: postgres:15-alpine
        container_name: postgres-resume
        restart: unless-stopped
        volumes:
            - ./resume/postgres:/var/lib/postgresql/data
        environment:
            - POSTGRES_DB=postgres
            - POSTGRES_USER=postgres
            - POSTGRES_PASSWORD=postgres
        healthcheck:
            test: ["CMD-SHELL", "pg_isready -U postgres -d postgres"]
            interval: 10s
            timeout: 5s
            retries: 5
    minio-resume:
        container_name: minio-resume
        image: minio/minio
        restart: unless-stopped
        command: server /data
        ports:
            - 9000:9000
        volumes:
            - ./resume/minio:/data
        environment:
            - MINIO_ROOT_USER=minioadmin
            - MINIO_ROOT_PASSWORD=minioadmin
    chrome-resume:
        image: ghcr.io/browserless/chromium:latest
        container_name: chrome-resume
        restart: unless-stopped
        environment:
            - TOKEN=chrome_token
            - TIMEOUT=10000
            - EXIT_ON_HEALTH_FAILURE=true
            - PRE_REQUEST_HEALTH_CHECK=true
    redis-resume:
        image: redis:alpine
        container_name: redis-resume
        restart: unless-stopped
        command: redis-server --requirepass password
    resume:
        image: amruthpillai/reactive-resume:latest
        container_name: resume
        restart: unless-stopped
        ports:
            - 3000:3000
        environment:
            - PORT=3000
            - VITE_DISABLE_SIGNUPS = true
            - NODE_ENV=production
            # -- URLs --
            - PUBLIC_URL=https://rxresume.yanello.net
            - STORAGE_URL=https://minio.yanello.net/default
            # -- Printer (Chrome) --
            - CHROME_TOKEN=chrome_token
            - CHROME_URL=ws://chrome-resume:3000
            # -- Database (Postgres) --
            - DATABASE_URL=postgresql://postgres:postgres@postgres-resume:5432/postgres
            # -- Auth --
            - ACCESS_TOKEN_SECRET=access_token_secret
            - REFRESH_TOKEN_SECRET=refresh_token_secret
            # -- Emails --
            #- MAIL_FROM=marcus.yanello@gmail.com
            #-SMTP_URL=smtp://user:pass@smtp:587 # Optional
            # -- Storage (Minio) --
            - STORAGE_ENDPOINT=minio-resume
            - STORAGE_PORT=9000
            #STORAGE_REGION: us-east-1 # Optional
            - STORAGE_BUCKET=default
            - STORAGE_ACCESS_KEY=minioadmin
            - STORAGE_SECRET_KEY=minioadmin
            - STORAGE_USE_SSL=false
            # -- Cache (Redis) --
            - REDIS_URL=redis://default:password@redis-resume:6379

    #    focus:
    #        container_name: focus
    #        build:
    #            context: ./focus
    #            dockerfile: Dockerfile
    #        volumes:
    #        - ./focus-data/data:/content/data
    #        restart: unless-stopped
    #        ports:
    #        - 7865:7865
    #        environment:
    #        - CMDARGS=--listen    # Arguments for launch.py.
    #        - DATADIR=/content/data   # Directory which stores models, outputs dir
    #        - config_path=/content/data/config.txt
    #        - config_example_path=/content/data/config_modification_tutorial.txt
    #        - path_checkpoints=/content/data/models/checkpoints/
    #        - path_loras=/content/data/models/loras/
    #        - path_embeddings=/content/data/models/embeddings/
    #        - path_vae_approx=/content/data/models/vae_approx/
    #        - path_upscale_models=/content/data/models/upscale_models/
    #        - path_inpaint=/content/data/models/inpaint/
    #        - path_controlnet=/content/data/models/controlnet/
    #        - path_clip_vision=/content/data/models/clip_vision/
    #        - path_fooocus_expansion=/content/data/models/prompt_expansion/fooocus_expansion/
    #        - path_outputs=/content/app/outputs/    # Warning: If it is not located under '/content/app', you can't see history log!
    ##        tty: true
    #        deploy:
    #            resources:
    #                reservations:
    #                    devices:
    #                    - driver: nvidia
    #                      capabilities: [gpu, compute, utility]
    #                      count: 1

    registry:
        container_name: registry
        image: registry:2
        ports:
            - 5300:5000
        environment:
            - REGISTRY_STORAGE_FILESYSTEM_ROOTDIRECTORY=/data
        #        - REGISTRY_AUTH=htpasswd
        #        - REGISTRY_AUTH_HTPASSWD_REALM=Registry Realm
        #        - REGISTRY_AUTH_HTPASSWD_PATH:/auth/registry.password
        volumes:
            - ./registry/data:/data
            - ./registry/auth:/auth

    plex:
        container_name: plex
        image: plexinc/pms-docker
        volumes:
            - ./plex/database:/config
            - ./plex/transcode:/transcode
            - /data/media:/data/media
        environment:
            - TZ="America/Chicago"
            - PLEX_CLAIM=$PLEX_CLAIM
            - ALLOWED_NETWORKS=192.168.0.0/16
            - PLEX_UID=1000
            - PLEX_GID=1000
            - NVIDIA_VISIBLE_DEVICES=all
            - NVIDIA_DRIVER_CAPABILITIES=all
        network_mode: host
        restart: no
        deploy:
            resources:
                limits:
                    cpus: "0.7"
                reservations:
                    devices:
                        - driver: nvidia
                          count: 1
                          capabilities: [gpu]

    changedet:
        container_name: changedet
        image: ghcr.io/dgtlmoon/changedetection.io
        volumes:
            - ./changedet:/datastore
        ports:
            - 5025:5000
        restart: unless-stopped
        environment:
            #- WEBDRIVER_URL=http://browser-chome:4444/wd/hub
            - PLAYWRIGHT_DRIVER_URL=ws://playwright:3000/?stealth=1&--disable-web-security=true
            - BASE_URL='https://change.yanello.net'
    playwright:
        container_name: playwright
        restart: unless-stopped
        image: browserless/chrome:1.60-chrome-stable
        hostname: playwright
        environment:
            - SCREEN_WIDTH=1920
            - SCREEN_HEIGHT=1024
            - SCREEN_DEPTH=16
            - ENABLE_DEBUGGER=false
            - PREBOOT_CHROME=true
            - CONNECTION_TIMEOUT=300000
            - MAX_CONCURRENT_SESSIONS=10
            - CHROME_REFRESH_TIME=600000
            - DEFAULT_BLOCK_ADS=true
            - DEFAULT_STEALTH=true
            - DEFAULT_IGNORE_HTTPS_ERRORS=true

    owntracks:
        container_name: owntracks
        volumes:
            - ./owntracks:/store
        environment:
            - OTR_HOST=192.168.1.4
            - OTR_USER=mosquitto
            - OTR_PASS=${MQTT_PASS}
        image: owntracks/recorder
        ports:
            - 60833:8083

    kuma:
        container_name: kuma
        volumes:
            - ./kuma:/app/data
        ports:
            - 3001:3001
        restart: unless-stopped
        image: louislam/uptime-kuma

    yn-pg:
        container_name: yn-pg
        image: postgres
        restart: unless-stopped
        volumes:
            - ./yn-pg:/var/lib/postgresql/data
        environment:
            - POSTGRES_PASSWORD=${postgres_password}
            - POSTGRES_DB=yanellonet
            - POSTGRES_USER=${postgres_username}
        #ports:
        #- 3203:5432

    netdisco-postgresql:
        image: netdisco/netdisco:latest-postgresql
        hostname: netdisco-postgresql
        volumes:
            - "./netdisco/pgdata:/var/lib/postgresql/data"
        container_name: netdisco-psql
    netdisco-backend:
        image: netdisco/netdisco:latest-backend
        hostname: netdisco-backend
        init: true
        volumes:
            - "./netdisco/nd-site-local:/home/netdisco/nd-site-local"
            - "./netdisco/config:/home/netdisco/environments"
            - "./netdisco/logs:/home/netdisco/logs"
        environment:
            NETDISCO_DOMAIN: discover
            NETDISCO_DB_HOST: netdisco-postgresql
        dns_opt:
            - "ndots:0"
            - "timeout:1"
            - "retries:0"
            - "attempts:1"
            - edns0
            - trustad
        container_name: netdisco-backend
    netdisco-web:
        image: netdisco/netdisco:latest-web
        hostname: netdisco-web
        init: true
        volumes:
            - "./netdisco/nd-site-local:/home/netdisco/nd-site-local"
            - "./netdisco/config:/home/netdisco/environments"
        environment:
            NETDISCO_DOMAIN: discover
            NETDISCO_DB_HOST: netdisco-postgresql
            IPV: 4
        ports:
            - "5020:5000"
        dns_opt:
            - "ndots:0"
            - "timeout:1"
            - "retries:0"
            - "attempts:1"
            - edns0
            - trustad
        container_name: netdisco-web
    netdisco-do:
        image: netdisco/netdisco:latest-do
        # use same hostname as backend to satisfy skiplist check (#68)
        hostname: netdisco-backend
        volumes:
            - "./netdisco/nd-site-local:/home/netdisco/nd-site-local"
            - "./netdisco/config:/home/netdisco/environments"
        environment:
            NETDISCO_DOMAIN: discover
            NETDISCO_DB_HOST: netdisco-postgresql
        profiles:
            - cli-manual
        container_name: netdisco-do

    calibre:
        image: crocodilestick/calibre-web-automated:latest
        container_name: calibre
        environment:
            - PUID=1000
            - PGID=1000
            - TZ=America/Chicago
            - DOCKER_MODS=lscr.io/linuxserver/mods:universal-calibre-v7.16.0
        volumes:
            - ./calibre/config:/config
            - ./calibre/ingest:/cwa-book-ingest
            - ./calibre/library:/calibre-library
        ports:
            - 8083:8083
        restart: unless-stopped
    calibre-downloader:
        container_name: calibre-downloader
        image: ghcr.io/calibrain/calibre-web-automated-book-downloader:latest
        environment:
            - FLASK_PORT=8084
            - FLAST_DEBUG=false
            - CLOUDFLARE_PROXY_URL=http://cloudflarebypassforscraping:8000
            - INGEST_DIR=/cwa-book-ingest
            - BOOK_LANGUAGE=en
        ports:
            - 7835:8084
        restart: unless-stopped
        volumes:
            - ./calibre/ingest:/cwa-book-ingest
    cloudflarebypassforscraping:
        image: ghcr.io/sarperavci/cloudflarebypassforscraping:latest
        restart: unless-stopped

    backrest:
        image: garethgeorge/backrest:latest
        container_name: backrest
        hostname: backrest
        volumes:
            - ./backrest/data:/data
            - ./backrest/config:/config
            - ./backrest/cache:/cache
            - /zpool/docker:/userdata/zpool/docker
            - /etc:/userdata/etc
            - /zpool/k8s:/userdata/zpool/k8s
            - /data/media/assets/:/userdata/data/media/assets
            - /zpool/Photos/:/userdata/zpool/Photos
            - /zpool/share/:/userdata/zpool/share
            - /mnt/desktop/backups/restic/:/userdata/mnt/desktop/backups/restic
            - /data/backup/restic/:/userdata/data/backup/restic
            - /data/backup/restic:/repos
        environment:
            - BACKREST_DATA=/data # path for backrest data. restic binary and the database are placed here.
            - BACKREST_CONFIG=/config/config.json # path for the backrest config file.
            - XDG_CACHE_HOME=/cache # path for the restic cache which greatly improves performance.
            - TZ=America/Chicago # set the timezone for the container, used as the timezone for cron jobs.
        restart: unless-stopped
        ports:
            - 9898:9898

    open-webui:
        image: ghcr.io/open-webui/open-webui:ollama
        container_name: open-webui
        restart: unless-stopped
        environment:
            - OLLAMA_HOST=0.0.0.0
        volumes:
            - ./openweb-ui/data:/app/backend/data
            - ./openweb-ui/ollama:/root/.ollama
        ports:
            - 30037:8080
            - 11434:11434 # ollama port
        deploy:
            resources:
                reservations:
                    devices:
                        - driver: nvidia
                          count: 1
                          capabilities: [gpu]

    wallos:
        image: bellamy/wallos:latest
        container_name: wallos
        ports:
            - 8282:80
        environment:
            - TZ=America/Chicago
        volumes:
            - ./wallos/db:/var/www/html/db
            - ./wallos/logos:/var/www/html/images/uploads/logos
        restart: unless-stopped

#    healthstats:
#        container_name: healthstats
#        build:
#          context: ./healthstats-collector/
#          dockerfile: Dockerfile.cron.amd64
#        env_file: ./healthstats-collector/.env
#        restart: always
#    pushgateway:
#        image: prom/pushgateway
#        container_name: pushgateway
#        restart: unless-stopped
#        expose:
#        - 9091
#        ports:
#        - 9091:9091
#    pg-linkwarden:
#      image: postgres:16-alpine
#      env_file: ./env/linkwarden.env
#      restart: always
#      container_name: pg-linkwarden
#      volumes:
#        - ./linkwarden/pgdata:/var/lib/postgresql/data
#    linkwarden:
#      container_name: linkwarden
#      env_file: ./env/linkwarden.env
#      restart: always
#      image: ghcr.io/linkwarden/linkwarden:latest
#      ports:
#        - 3371:3371
#      environment:
#        - DATABASE_URL=postgresql://postgres:${POSTGRES_PASSWORD}@pg-linkwarden:5432/postgres
#      volumes:
#        - ./linkwarden/data:/data/data
#      depends_on:
#        - pg-linkwarden
#
#    db_recipes:
#        restart: always
#        image: postgres:16-alpine
#        volumes:
#        - ./recipes/psql:/var/lib/postgresql/data
#        env_file:
#        - ./env/recipes.env
#        container_name: db_recipes
#    web_recipes:
#        container_name: web_recipes
#        restart: always
#        image: vabene1111/recipes
#        env_file:
#        - ./env/recipes.env
#        volumes:
#        - staticfiles:/opt/recipes/staticfiles
#        - nginx_config:/opt/recipes/nginx/conf.d
#        - ./recipes/mediafiles:/opt/recipes/mediafiles
#        ports:
#            - 4789:80
#    nginx_recipes:
#        container_name: nginx_recipes
#        restart: always
#        image: nginx:mainline-alpine
#        ports:
#        - 4789:80
#        env_file:
#        - ./env/recipes.env
#        depends_on:
#        - web_recipes
#        volumes:
#        - nginx_config:/etc/nginx/conf.d:ro
#        - staticfiles:/static:ro
#        - ./recipes/mediafiles:/media:ro
# swagger:
#     container_name: swagger
#     image: swaggerapi/swagger-ui
#     ports:
#     - 80:8395

networks:
    nextcloud_net:
        ipam:
            config:
                - subnet: 172.20.0.0/16
                  ip_range: 172.20.0.0/24
